---
layout: post
type: 'Process'
title:  "Hidden Archives"
date:   2018-05-15 21:09:29 +0100
---


This project started primarily as an excuse for me to learn about machine learning, which seemed like a smart career move.
I worked my way through 

As with the drawing machine project, I took [contemporaneous notes](http://www.maxkoehler.com/2018/feret-database/)

![iPhone](/assets/ml/iphone.jpg)

![Pixel RNN](/assets/ml/test_arange_17.png)
Images generated by Pixel-RNN (trained for 100 epochs on the FERET Database) 

(I tried making things, this spun off into news clippings)

At this point the project shifted from being process-based and focussd on outcomes (like the drawing machines) to being more research-driven. I was looking at 

<p class='full'>
<img  src='/assets/ml/feret-explorer.png'/>
The FERET Database
</p>

<p class='full'>
<img  src='/assets/ml/drawings.png'/>
Drawings of the FERET Database
</p>

<p class='full'>
<img  src='/assets/ml/swb1.png'/>
Switchboard Corpus
</p>

<p class='full'>
<img  src='/assets/ml/mugshots.png'/>
NIST Special Database 32 (Mugshots)
</p>

<p class='full'>
<img  src='/assets/ml/warhol.jpg'/>
Youtube Faces
</p>

<div class='masonry-2 full hasImage' markdown='1'>
![ATT](/assets/ml/faces.gif)
![gait](/assets/ml/gait-11.png)
![gait](/assets/ml/gait-13.png)
</div>

<p class='full'>
<div style="padding:70% 0 0 0;position:relative;"><iframe src="https://player.vimeo.com/video/272658961?color=ffffff&title=0&byline=0&portrait=0" style="position:absolute;top:0;left:0;width:100%;height:100%;" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe></div>
Google Robot Motion Database
</p>

![Data extraction](/assets/ml/Capture-14.PNG)

These databases aren't meant for humans to look at, even in terms of file formats. Nearly every dataset I looked at came in some compressed format, together with heaps of (to me) useless meta-data. I spent hours writing special one-off programs to read these files, extract the relevant data and save it into a format I could work with.

## Secondary Research

![Machine drawing](/assets/ml/richter.jpg)
Gerhardt Richter: 48 Portaits (1971-98) [Tate](http://www.tate.org.uk/art/artworks/richter-48-portraits-ar00025)

Stuff on the politics of the archive

![Bertillion](/assets/ml/bertillon.jpg)
Bertillion [The Metropolitan Museum of Art](https://www.metmuseum.org/art/collection/search/289245?sortBy=Relevance&ft=alphonse+bertillon&offset=0&rpp=20&pos=1)

readings here

unearthing government things


<p class='full masonry-2'>
<img  src='/assets/machines/sultan_mandel_0.jpg'/>
<img  src='/assets/machines/sultan_mandel_1.jpg'/>
</p>

<p class='full masonry-2'>
<img  src='/assets/ml/paglen-sky.jpg'/>
<img  src='/assets/ml/paglen-sky-2.jpg'/>
<img  src='/assets/ml/paglen-drone.jpg'/>
<img  src='/assets/ml/paglen-6.jpg'/>
Trevor Paglen
</p>

![Eigenface](/assets/ml/eigen.png)

## Outcomes


<div class='masonry-5 full hasImage' markdown='1'>
![Arc Studio](/assets/ml/arc-studio-graphic-design-itsnicethat-12-1.jpeg)
![Pop Art Mon Armour](/assets/ml/PopArtMonAmour-03.jpeg)
![Lars Muller 2](/assets/ml/30-years-of-swiss-typographic-discourse-02.png)
![Neubau](/assets/ml/neubau-forst-080-081.png)
![Eatock](/assets/ml/Eatock3.jpeg)
![Finn](/assets/ml/finn1.jpg)
![Finn](/assets/ml/finn2.jpg)
![Letraset by unit Editions](/assets/ml/unit.jpg)
![Lars Muller](/assets/ml/positions-on-emancipations.png)
![Lars Muller 3](/assets/ml/roberto-burle-marx-lectures.png)
![Empire 1](/assets/ml/empire-1.jpg)
![Empire 2](/assets/ml/empire-2.png)
</div>

I made various attempts to visualise the machine learning datasets I was looking at. Each one is different, requiring a different mode of presentation.

I printed a spreadsheet containing anonymised data about American criminals at a large format.

![FERET](/assets/ml/feret-test.jpg)
![FERET](/assets/ml/feret-grid.jpg)
I had part of the FERET database reproduced as C-type prints and hung them in a grid to emphasise its scale and strictly controlled aesthetics. I 3d-rendered and animated part of the Gait dataset. The terms of use of these databases usually ban online reproduction  of any significant portion of them, which is the point of the project.

Eventually, the book emerged as a good medium for a number of reasons: 

- It would allow me to reproduce a larger share of the databases (though that share is still small).
- It takes these databases out of their natural, digital context and make the accessible in a physical form. The way the books are designed (small format, traditional typography, off-white paper) supports this idea of creating a decidedly non-digital space.
- Finally, a printed outcome gets around the licensing agreements of many datasets which prohibit online reproduction.


<div class='masonry-2 bleed' markdown='1'>
![Machine drawing](/assets/ml/Capture.PNG)
![Machine drawing](/assets/ml/Capture-1.PNG)
![Machine drawing](/assets/ml/Capture-4.PNG)
![Machine drawing](/assets/ml/Capture-5.PNG)
![Machine drawing](/assets/ml/Capture-6.PNG)
![Machine drawing](/assets/ml/Capture-7.PNG)
![Machine drawing](/assets/ml/Capture-8.PNG)
![Machine drawing](/assets/ml/Capture-11.PNG)
![Machine drawing](/assets/ml/Capture-12.PNG)
![Machine drawing](/assets/ml/Capture-13.PNG)
![Machine drawing](/assets/ml/Capture-15.PNG)
![Machine drawing](/assets/ml/Capture-16.PNG)
![Machine drawing](/assets/ml/Capture-17.PNG)
![Machine drawing](/assets/ml/Capture-21.PNG)
</div>

## Production

<p class='full' style="padding:70% 0 0 0;position:relative;"><iframe src="https://player.vimeo.com/video/271334302?autoplay=1&loop=1" style="position:absolute;top:-2rem;left:0;width:100%;height:100%;" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen></iframe>
Timelapse of me perfect-binding a book and working on the degree show website
</p>

<div class="masonry-2 full">
<img src='/assets/ml/wall-full.jpg' alt='ML Book protoypes'>
<img src='/assets/ml/spread.jpg' alt='ML Book protoypes'>
<img src='/assets/ml/book-prototype.jpg' alt='ML Book protoypes'>
<img src='/assets/ml/book-shims.jpg' alt='ML Book protoypes'>
<img src='/assets/ml/spread-2.jpg' alt='ML Book protoypes'/>
<img src='/assets/ml/binding-setup.jpg' alt='Binding setup'/>
<img src='/assets/ml/book-prototypes.jpg'  alt='ML Book protoypes'>
<img src='/assets/ml/paper-samples.jpg'  alt='ML Book protoypes'>
</div>

I decided to print the books myself on a laserjet and perfect-bind them by hand. I had a few reasons for this:

- Since I couldn't afford offset or risograph printing (and both would be silly to do for a tiny edition) digital print seemed like my only option. I didn't see how a commercial printer would produce significantly better results than I could, especially since the books are black and white. 
- Doing the printing myself meant there wasn't a print-deadline - I could print the books the night before handin if I had to. This gave me a few more weeks to work on the writing and editorial design.
- I could use my own paper. From what I've gathered, printers won't generally let you use named papers (i.e the stuff that's in the G.F. Smith sample book) unless you're ordering big runs. Getting technical about paper - comparing different weights, ordering samples, doing test prints, working out grain directions - was perhps the most enjoyable part of the project.
- It allowed me to make protoypes as I was designing the book. I could run test prints on different stocks and practice my binding technique knowing that what I was looking at would be very close to the final product. I first saw this way of working at [GTF](http://www.graphicthoughtfacility.com/) - of course, they have the budgets to order up test prints from a commercial printer.


All are printed on [Southbank Book White 115g](http://www.johnpurcell.net/sbank.html) (front matter), [Heritage Bookwhite 100g](http://www.johnpurcell.net/heriwoodCON.html) (body) and [Colorplan Pale Grey 270g](http://colorplanpapers.com/50colours) (Covers).

I think the Colorplan and Heritage papers are succesful in their applications. However, I don't think there's enough of a contrast (in weight, texture or colour) between the Southbank and Heritage stocks to make to create hierarchy. It's the equivalent of pairing Arial and Helvetica - it just creates visual noise.   
